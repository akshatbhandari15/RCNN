{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pacific-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['37261', '37913', '37914', '37915', '37916']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)\n",
    "\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "biblical-browser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriented-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prime-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expensive-faith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'of']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quick-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "formal-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = r\"C:\\Users\\aksha\\Desktop\\TensorFlow\\glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gorgeous-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "precise-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 18019 words (1981 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "laden-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "organic-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         2000200   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         84480     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 2,185,820\n",
      "Trainable params: 185,620\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sporting-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mysterious-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "125/125 [==============================] - 52s 418ms/step - loss: 0.6833 - acc: 0.7710 - val_loss: 0.8535 - val_acc: 0.7239\n",
      "Epoch 2/40\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.6153 - acc: 0.7895 - val_loss: 0.8135 - val_acc: 0.7347\n",
      "Epoch 3/40\n",
      "125/125 [==============================] - 53s 427ms/step - loss: 0.5734 - acc: 0.8042 - val_loss: 0.8834 - val_acc: 0.7219\n",
      "Epoch 4/40\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.5197 - acc: 0.8235 - val_loss: 0.8045 - val_acc: 0.7377\n",
      "Epoch 5/40\n",
      "125/125 [==============================] - 53s 423ms/step - loss: 0.4771 - acc: 0.8340 - val_loss: 0.8197 - val_acc: 0.7432\n",
      "Epoch 6/40\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.4362 - acc: 0.8504 - val_loss: 0.8745 - val_acc: 0.7404\n",
      "Epoch 7/40\n",
      "125/125 [==============================] - 53s 424ms/step - loss: 0.3949 - acc: 0.8641 - val_loss: 0.8462 - val_acc: 0.7332\n",
      "Epoch 8/40\n",
      "125/125 [==============================] - 53s 426ms/step - loss: 0.3594 - acc: 0.8765 - val_loss: 0.8677 - val_acc: 0.7482\n",
      "Epoch 9/40\n",
      "125/125 [==============================] - 53s 425ms/step - loss: 0.3242 - acc: 0.8859 - val_loss: 0.8698 - val_acc: 0.7457\n",
      "Epoch 10/40\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.3036 - acc: 0.8933 - val_loss: 0.9293 - val_acc: 0.7402\n",
      "Epoch 11/40\n",
      "125/125 [==============================] - 53s 423ms/step - loss: 0.2682 - acc: 0.9062 - val_loss: 0.9305 - val_acc: 0.7439\n",
      "Epoch 12/40\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.2502 - acc: 0.9100 - val_loss: 0.9527 - val_acc: 0.7447\n",
      "Epoch 13/40\n",
      "125/125 [==============================] - 55s 444ms/step - loss: 0.2311 - acc: 0.9167 - val_loss: 0.9805 - val_acc: 0.7454\n",
      "Epoch 14/40\n",
      "125/125 [==============================] - 54s 430ms/step - loss: 0.2138 - acc: 0.9239 - val_loss: 1.0032 - val_acc: 0.7507\n",
      "Epoch 15/40\n",
      "125/125 [==============================] - 54s 436ms/step - loss: 0.1937 - acc: 0.9312 - val_loss: 1.0238 - val_acc: 0.7487\n",
      "Epoch 16/40\n",
      "125/125 [==============================] - 55s 440ms/step - loss: 0.1834 - acc: 0.9366 - val_loss: 1.0333 - val_acc: 0.7467\n",
      "Epoch 17/40\n",
      "125/125 [==============================] - 54s 433ms/step - loss: 0.1705 - acc: 0.9394 - val_loss: 1.0806 - val_acc: 0.7459\n",
      "Epoch 18/40\n",
      "125/125 [==============================] - 53s 427ms/step - loss: 0.1616 - acc: 0.9428 - val_loss: 1.0554 - val_acc: 0.7544\n",
      "Epoch 19/40\n",
      "125/125 [==============================] - 52s 420ms/step - loss: 0.1494 - acc: 0.9468 - val_loss: 1.1149 - val_acc: 0.7517\n",
      "Epoch 20/40\n",
      "125/125 [==============================] - 53s 427ms/step - loss: 0.1526 - acc: 0.9471 - val_loss: 1.1158 - val_acc: 0.7567\n",
      "Epoch 21/40\n",
      "125/125 [==============================] - 52s 419ms/step - loss: 0.1382 - acc: 0.9498 - val_loss: 1.1598 - val_acc: 0.7349\n",
      "Epoch 22/40\n",
      "125/125 [==============================] - 53s 426ms/step - loss: 0.1336 - acc: 0.9520 - val_loss: 1.1431 - val_acc: 0.7524\n",
      "Epoch 23/40\n",
      "125/125 [==============================] - 53s 423ms/step - loss: 0.1430 - acc: 0.9497 - val_loss: 1.1002 - val_acc: 0.7529\n",
      "Epoch 24/40\n",
      "125/125 [==============================] - 53s 426ms/step - loss: 0.1268 - acc: 0.9533 - val_loss: 1.1962 - val_acc: 0.7547\n",
      "Epoch 25/40\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.1311 - acc: 0.9511 - val_loss: 1.2082 - val_acc: 0.7487\n",
      "Epoch 26/40\n",
      "125/125 [==============================] - 53s 421ms/step - loss: 0.1178 - acc: 0.9575 - val_loss: 1.1747 - val_acc: 0.7464\n",
      "Epoch 27/40\n",
      "125/125 [==============================] - 54s 429ms/step - loss: 0.1115 - acc: 0.9589 - val_loss: 1.2586 - val_acc: 0.7504\n",
      "Epoch 28/40\n",
      "125/125 [==============================] - 57s 453ms/step - loss: 0.1076 - acc: 0.9598 - val_loss: 1.2409 - val_acc: 0.7432\n",
      "Epoch 29/40\n",
      "125/125 [==============================] - 54s 434ms/step - loss: 0.1014 - acc: 0.9608 - val_loss: 1.2232 - val_acc: 0.7477\n",
      "Epoch 30/40\n",
      "125/125 [==============================] - 55s 437ms/step - loss: 0.0992 - acc: 0.9622 - val_loss: 1.2677 - val_acc: 0.7474\n",
      "Epoch 31/40\n",
      "125/125 [==============================] - 54s 433ms/step - loss: 0.1006 - acc: 0.9611 - val_loss: 1.3097 - val_acc: 0.7492\n",
      "Epoch 32/40\n",
      "125/125 [==============================] - 55s 438ms/step - loss: 0.0982 - acc: 0.9624 - val_loss: 1.3132 - val_acc: 0.7432\n",
      "Epoch 33/40\n",
      "125/125 [==============================] - 54s 432ms/step - loss: 0.1070 - acc: 0.9601 - val_loss: 1.3174 - val_acc: 0.7464\n",
      "Epoch 34/40\n",
      "125/125 [==============================] - 54s 433ms/step - loss: 0.0996 - acc: 0.9591 - val_loss: 1.3082 - val_acc: 0.7589\n",
      "Epoch 35/40\n",
      "125/125 [==============================] - 54s 433ms/step - loss: 0.0968 - acc: 0.9607 - val_loss: 1.3354 - val_acc: 0.7399\n",
      "Epoch 36/40\n",
      "125/125 [==============================] - 54s 435ms/step - loss: 0.0954 - acc: 0.9609 - val_loss: 1.3471 - val_acc: 0.7459\n",
      "Epoch 37/40\n",
      "125/125 [==============================] - 55s 440ms/step - loss: 0.0892 - acc: 0.9647 - val_loss: 1.3564 - val_acc: 0.7469\n",
      "Epoch 38/40\n",
      "125/125 [==============================] - 58s 464ms/step - loss: 0.0904 - acc: 0.9624 - val_loss: 1.3631 - val_acc: 0.7487\n",
      "Epoch 39/40\n",
      "125/125 [==============================] - 59s 473ms/step - loss: 0.0825 - acc: 0.9657 - val_loss: 1.3851 - val_acc: 0.7519\n",
      "Epoch 40/40\n",
      "125/125 [==============================] - 55s 438ms/step - loss: 0.0913 - acc: 0.9617 - val_loss: 1.3087 - val_acc: 0.7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c390202e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"]\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=40, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "animated-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-disabled",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

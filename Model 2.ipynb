{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pursuant-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pacific-patent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['37261', '37913', '37914', '37915', '37916']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)\n",
    "\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "likely-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "selected-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competitive-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "generous-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = r\"C:\\Users\\aksha\\Desktop\\TensorFlow\\glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hawaiian-vancouver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "descending-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 18019 words (1981 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "palestinian-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continued-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         2000200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 200)         160800    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 2,189,308\n",
      "Trainable params: 189,108\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(100, return_sequences=True))(embedded_sequences)\n",
    "\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "challenging-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "short-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "125/125 [==============================] - 78s 620ms/step - loss: 2.2257 - acc: 0.2892 - val_loss: 1.5593 - val_acc: 0.4489\n",
      "Epoch 2/40\n",
      "125/125 [==============================] - 82s 654ms/step - loss: 1.3826 - acc: 0.5336 - val_loss: 1.2932 - val_acc: 0.5584\n",
      "Epoch 3/40\n",
      "125/125 [==============================] - 84s 670ms/step - loss: 1.1211 - acc: 0.6248 - val_loss: 1.0747 - val_acc: 0.6334\n",
      "Epoch 4/40\n",
      "125/125 [==============================] - 92s 740ms/step - loss: 0.9609 - acc: 0.6841 - val_loss: 0.9946 - val_acc: 0.6617\n",
      "Epoch 5/40\n",
      "125/125 [==============================] - 85s 682ms/step - loss: 0.8644 - acc: 0.7103 - val_loss: 0.8987 - val_acc: 0.7032\n",
      "Epoch 6/40\n",
      "125/125 [==============================] - 86s 687ms/step - loss: 0.7860 - acc: 0.7399 - val_loss: 0.8983 - val_acc: 0.6977\n",
      "Epoch 7/40\n",
      "125/125 [==============================] - 86s 689ms/step - loss: 0.7097 - acc: 0.7677 - val_loss: 0.8288 - val_acc: 0.7229\n",
      "Epoch 8/40\n",
      "125/125 [==============================] - 86s 686ms/step - loss: 0.6452 - acc: 0.7882 - val_loss: 0.8158 - val_acc: 0.7359\n",
      "Epoch 9/40\n",
      "125/125 [==============================] - 86s 686ms/step - loss: 0.5944 - acc: 0.8029 - val_loss: 0.7791 - val_acc: 0.7467\n",
      "Epoch 10/40\n",
      "125/125 [==============================] - 85s 683ms/step - loss: 0.5345 - acc: 0.8221 - val_loss: 0.7755 - val_acc: 0.7437\n",
      "Epoch 11/40\n",
      "125/125 [==============================] - 86s 689ms/step - loss: 0.4827 - acc: 0.8407 - val_loss: 0.7625 - val_acc: 0.7462\n",
      "Epoch 12/40\n",
      "125/125 [==============================] - 86s 687ms/step - loss: 0.4281 - acc: 0.8604 - val_loss: 0.7550 - val_acc: 0.7519\n",
      "Epoch 13/40\n",
      "125/125 [==============================] - 87s 696ms/step - loss: 0.3889 - acc: 0.8730 - val_loss: 0.7580 - val_acc: 0.7534\n",
      "Epoch 14/40\n",
      "125/125 [==============================] - 87s 696ms/step - loss: 0.3561 - acc: 0.8867 - val_loss: 0.7664 - val_acc: 0.7572\n",
      "Epoch 15/40\n",
      "125/125 [==============================] - 86s 692ms/step - loss: 0.3118 - acc: 0.8995 - val_loss: 0.7656 - val_acc: 0.7614\n",
      "Epoch 16/40\n",
      "125/125 [==============================] - 87s 694ms/step - loss: 0.2833 - acc: 0.9098 - val_loss: 0.7636 - val_acc: 0.7689\n",
      "Epoch 17/40\n",
      "125/125 [==============================] - 86s 689ms/step - loss: 0.2448 - acc: 0.9223 - val_loss: 0.7787 - val_acc: 0.7657\n",
      "Epoch 18/40\n",
      "125/125 [==============================] - 86s 691ms/step - loss: 0.2178 - acc: 0.9322 - val_loss: 0.7871 - val_acc: 0.7594\n",
      "Epoch 19/40\n",
      "125/125 [==============================] - 94s 751ms/step - loss: 0.1921 - acc: 0.9400 - val_loss: 0.7912 - val_acc: 0.7642\n",
      "Epoch 20/40\n",
      "125/125 [==============================] - 94s 749ms/step - loss: 0.1783 - acc: 0.9435 - val_loss: 0.8015 - val_acc: 0.7699\n",
      "Epoch 21/40\n",
      "125/125 [==============================] - 90s 722ms/step - loss: 0.1604 - acc: 0.9503 - val_loss: 0.8707 - val_acc: 0.7582\n",
      "Epoch 22/40\n",
      "125/125 [==============================] - 91s 725ms/step - loss: 0.1489 - acc: 0.9539 - val_loss: 0.8404 - val_acc: 0.7624\n",
      "Epoch 23/40\n",
      "125/125 [==============================] - 90s 722ms/step - loss: 0.1409 - acc: 0.9563 - val_loss: 0.8589 - val_acc: 0.7672\n",
      "Epoch 24/40\n",
      "125/125 [==============================] - 90s 721ms/step - loss: 0.1247 - acc: 0.9595 - val_loss: 0.8873 - val_acc: 0.7577\n",
      "Epoch 25/40\n",
      "125/125 [==============================] - 88s 705ms/step - loss: 0.1174 - acc: 0.9615 - val_loss: 0.9238 - val_acc: 0.7609\n",
      "Epoch 26/40\n",
      "125/125 [==============================] - 87s 700ms/step - loss: 0.1184 - acc: 0.9619 - val_loss: 0.9129 - val_acc: 0.7572\n",
      "Epoch 27/40\n",
      "125/125 [==============================] - 87s 699ms/step - loss: 0.1115 - acc: 0.9637 - val_loss: 0.9458 - val_acc: 0.7582\n",
      "Epoch 28/40\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.1125 - acc: 0.9643 - val_loss: 0.9200 - val_acc: 0.7634\n",
      "Epoch 29/40\n",
      "125/125 [==============================] - 87s 694ms/step - loss: 0.1013 - acc: 0.9648 - val_loss: 0.9356 - val_acc: 0.7682\n",
      "Epoch 30/40\n",
      "125/125 [==============================] - 88s 702ms/step - loss: 0.1031 - acc: 0.9652 - val_loss: 0.9840 - val_acc: 0.7589\n",
      "Epoch 31/40\n",
      "125/125 [==============================] - 87s 700ms/step - loss: 0.0969 - acc: 0.9659 - val_loss: 0.9475 - val_acc: 0.7664\n",
      "Epoch 32/40\n",
      "125/125 [==============================] - 86s 690ms/step - loss: 0.0969 - acc: 0.9670 - val_loss: 0.9377 - val_acc: 0.7674\n",
      "Epoch 33/40\n",
      "125/125 [==============================] - 86s 690ms/step - loss: 0.1152 - acc: 0.9606 - val_loss: 0.9532 - val_acc: 0.7664\n",
      "Epoch 34/40\n",
      "125/125 [==============================] - 84s 676ms/step - loss: 0.0930 - acc: 0.9672 - val_loss: 1.0104 - val_acc: 0.7619\n",
      "Epoch 35/40\n",
      "125/125 [==============================] - 93s 741ms/step - loss: 0.0903 - acc: 0.9671 - val_loss: 0.9732 - val_acc: 0.7699\n",
      "Epoch 36/40\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0909 - acc: 0.9662 - val_loss: 0.9751 - val_acc: 0.7709\n",
      "Epoch 37/40\n",
      "125/125 [==============================] - 96s 764ms/step - loss: 0.0854 - acc: 0.9689 - val_loss: 0.9965 - val_acc: 0.7719\n",
      "Epoch 38/40\n",
      "125/125 [==============================] - 93s 744ms/step - loss: 0.0861 - acc: 0.9684 - val_loss: 0.9922 - val_acc: 0.7694\n",
      "Epoch 39/40\n",
      "125/125 [==============================] - 95s 757ms/step - loss: 0.0885 - acc: 0.9671 - val_loss: 1.0144 - val_acc: 0.7634\n",
      "Epoch 40/40\n",
      "125/125 [==============================] - 94s 753ms/step - loss: 0.0856 - acc: 0.9687 - val_loss: 1.0999 - val_acc: 0.7627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2813449a970>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"]\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=40, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quarterly-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-bailey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
